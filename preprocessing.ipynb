{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP7cfRuW6EUQuPOOZ3RrVn7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f6d5c81f4d7349cbbebe495624649784":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3ea708cacc9f4259af54f0a8ec6acba3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_022c22a6ea2546ff82b5fbaef0c47094","IPY_MODEL_65295d392ca6403a83343fce00e4de13"]}},"3ea708cacc9f4259af54f0a8ec6acba3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"022c22a6ea2546ff82b5fbaef0c47094":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_607c737f783a4137a77b9deaf1dda1fe","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":15,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":15,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_912d9552906f4693b5aa69881c190c4e"}},"65295d392ca6403a83343fce00e4de13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f5a779c38fbd4054a3df62d1cca5b862","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15/15 [00:00&lt;00:00, 245.63it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c499c4b649649b693e612694fa0d7bb"}},"607c737f783a4137a77b9deaf1dda1fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"912d9552906f4693b5aa69881c190c4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5a779c38fbd4054a3df62d1cca5b862":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4c499c4b649649b693e612694fa0d7bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"Nd5iahbMKeAn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628526999557,"user_tz":-330,"elapsed":1707,"user":{"displayName":"Mahesh S B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJq2vPCCBeTPq7SaH9FGimM7i9a9Vs_m6EWe5OlIw=s64","userId":"00070032012763570688"}},"outputId":"f906eac0-dc95-4b6a-cbbc-7909a374fc90"},"source":["#Mount our google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2WCnnvUzKwC2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628527089389,"user_tz":-330,"elapsed":3061,"user":{"displayName":"Mahesh S B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJq2vPCCBeTPq7SaH9FGimM7i9a9Vs_m6EWe5OlIw=s64","userId":"00070032012763570688"}},"outputId":"2200af80-f312-472f-9486-428033052f37"},"source":["#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n","#download and unzip the data from google drive Colab environment\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","#use only file id of the link\n","#Note: Below link is just an example, Not an actual link. Actual Links are in ReadMe file\n","#https://drive.google.com/file/d/1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07/view?usp=sharing\n","\n","url = '1yofYRepuu2hLRMUhM3tL4sAJULhTuyHI'\n","gdd.download_file_from_google_drive(file_id = url,dest_path='./data.zip',unzip=True)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Downloading 1yofYRepuu2hLRMUhM3tL4sAJULhTuyHI into ./data.zip... Done.\n","Unzipping...Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pffx31xzz2v9","executionInfo":{"status":"ok","timestamp":1628527177727,"user_tz":-330,"elapsed":564,"user":{"displayName":"Mahesh S B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJq2vPCCBeTPq7SaH9FGimM7i9a9Vs_m6EWe5OlIw=s64","userId":"00070032012763570688"}},"outputId":"f3b7c4ad-5a6d-4591-acd4-30390d32c64b"},"source":["#To get the average frame count \n","import json\n","import glob\n","import numpy as np\n","import cv2\n","import copy\n","#change the path accordingly\n","video_files =  glob.glob('/content/preproc/*.mp4')  #3\n","#video_files1 =  glob.glob('/content/dfdc_train_part_0/*.mp4')\n","#video_files += video_files1\n","frame_count = []\n","for video_file in video_files:\n","  cap = cv2.VideoCapture(video_file) #4\n","  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150): #5 #6\n","    video_files.remove(video_file)\n","    continue\n","  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))  #7\n","print(\"frames\" , frame_count)\n","print(\"Total number of videos: \" , len(frame_count))\n","print('Average frame per video:',np.mean(frame_count))   #8\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["frames [300, 300, 300, 300, 299, 300, 300, 300, 300, 300, 299, 299, 300, 299, 300]\n","Total number of videos:  15\n","Average frame per video: 299.73333333333335\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TktDZsaw0sHX","executionInfo":{"status":"ok","timestamp":1628527255521,"user_tz":-330,"elapsed":41726,"user":{"displayName":"Mahesh S B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJq2vPCCBeTPq7SaH9FGimM7i9a9Vs_m6EWe5OlIw=s64","userId":"00070032012763570688"}},"outputId":"18ae01b1-f57a-4f8b-c5c4-2e6f0875daf9"},"source":["# to extract frame\n","def frame_extract(path):\n","  vidObj = cv2.VideoCapture(path)  #4\n","  success = 1\n","  while success:\n","      success, image = vidObj.read()\n","      if success:\n","          yield image\n","!pip3 install face_recognition\n","!mkdir '/content/drive/My Drive/Face_Only_Data1'\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import face_recognition\n","from tqdm.autonotebook import tqdm\n","# process the frames\n","def create_face_videos(path_list,out_dir):\n","  already_present_count =  glob.glob(out_dir+'*.mp4')    #3\n","  print(\"No of videos already present \" , len(already_present_count))\n","  for path in tqdm(path_list):\n","    out_path = os.path.join(out_dir,path.split('/')[-1])\n","    file_exists = glob.glob(out_path)\n","    if(len(file_exists) != 0):\n","      print(\"File Already exists: \" , out_path)\n","      continue\n","    frames = []\n","    flag = 0\n","    face_all = []\n","    frames1 = []\n","    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n","    for idx,frame in enumerate(frame_extract(path)):\n","      #if(idx % 3 == 0):\n","      if(idx <= 150):\n","        frames.append(frame)\n","        if(len(frames) == 4):\n","          faces = face_recognition.batch_face_locations(frames)\n","          for i,face in enumerate(faces):\n","            if(len(face) != 0):\n","              top,right,bottom,left = face[0]\n","            try:\n","              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n","            except:\n","              pass\n","          frames = []\n","    try:\n","      del top,right,bottom,left\n","    except:\n","      pass\n","    out.release()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.1 MB 9.0 kB/s \n","\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=da8e70eb35293763508f3666890875fc07554c27a8eca09da788a7ba029878a6\n","  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l0oYcuv04_ad"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334,"referenced_widgets":["f6d5c81f4d7349cbbebe495624649784","3ea708cacc9f4259af54f0a8ec6acba3","022c22a6ea2546ff82b5fbaef0c47094","65295d392ca6403a83343fce00e4de13","607c737f783a4137a77b9deaf1dda1fe","912d9552906f4693b5aa69881c190c4e","f5a779c38fbd4054a3df62d1cca5b862","4c499c4b649649b693e612694fa0d7bb"]},"id":"MMJ_6D4D1XxC","executionInfo":{"status":"ok","timestamp":1628529522009,"user_tz":-330,"elapsed":597,"user":{"displayName":"Mahesh S B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJq2vPCCBeTPq7SaH9FGimM7i9a9Vs_m6EWe5OlIw=s64","userId":"00070032012763570688"}},"outputId":"92eb7fce-466a-4f85-91df-0571c29e4cd4"},"source":["create_face_videos(video_files,'/content/drive/My Drive/Face_Only_Data1/')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["No of videos already present  15\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6d5c81f4d7349cbbebe495624649784","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["File Already exists:  /content/drive/My Drive/Face_Only_Data1/axfhbpkdlc.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/apvzjkvnwn.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/aktnlyqpah.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/ajiyrjfyzp.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/aassnaulhq.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/ahjnxtiamx.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/aayfryxljh.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/acazlolrpz.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/alrtntfxtd.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/ayipraspbn.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/aqrsylrzgi.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/aomqqjipcp.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/apedduehoy.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/bcbqxhziqz.mp4\n","File Already exists:  /content/drive/My Drive/Face_Only_Data1/adohdulfwb.mp4\n","\n"],"name":"stdout"}]}]}